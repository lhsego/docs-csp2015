## Housing Sales ##

### Data Description - Housing ###

The housing dataset contains data about housing sales aggregated to the 
county level in the United States between 2008-10-01 and 2014-03-01. These are 
Zillow.com data provided by [Quandl](https://www.quandl.com/c/housing). 
The data variables are as follows:

Variable | Description
---------|-----------------
fips | Federal Information Processing Standard, a 5 digit count code
county | US county name
state | US state name
time | date (the data is aggregated monthly)
nSold | number of homes sold this month
medListPriceSqft | median list price per square foot
medSoldPriceSqft | median sold price per square foot

### Trelliscope View - Housing ###

The purpose of this activity is to launch the `trelliscope` display and then explore the housing sales data: 
to look for patterns, trends, anomalies, etc. 
In this section, we'll show you the code required to launch a pre-created `trelliscope` view of the
data.

Let's begin by setting the working directory for this example. You will have to change the path 
in the command below to correctly point to the `housing_demo` directory.

```{r eval = TRUE}
# Set the working directory. Edit "~/correct_path" as necessary
setwd("~/correct_path/housing_demo")
```

And load the `trelliscope` and `housingData` packages:

```{r eval = TRUE, results = "hide", message = FALSE}
# Load packages
library(trelliscope)
library(housingData)
```

The following will launch two pre-made trelliscope displays:
- median list/sold price per sq ft vs time
- median list/sold price per sq ft vs time by state

Each panel represents the median listed (blue) and sold (pink) housing value plotted over time. 
Note that some of the panels only have one of the two values.  

Use `Cntrl-C` or `ESC` to stop the viewer and return to the R prompt.

```{r eval = FALSE, results = "hide", message = FALSE}
# Open the connection to the pre-existing trelliscope visualization. "vdb_housing" is a folder
# in the "housing_demo" folder, where we set the working directory earlier.
vdbConn("vdb_housing")

# use this port when running locally on your own computer
myport <- 8100 

# Launch the trelliscope viewer.  Use Ctrl-C or ESC to stop the reviewer and return
# the R prompt
view(port = myport)
```

### Challenge Questions - Housing ###

In order to familiarize 
yourself with the interface and get a sense of the features of the `trelliscope` package, see if 
you can answer the following set of questions:

1. Can you find the county with the largest positive slope in list price per square foot?  The slope is from a straight line
regression model that measures linear trend over time. (Hint: use the Table Sort/Filter or Univariate Filter)

2. Can you find the county with the largest negative slope? 

3. Can you find the state that has the largest range of county trends in list price? 
(Hint: use the Bivariate Filter)

4. Can you find the county with the largest increasing price trend in the South? 
(Hint: use the Table Sort/Filter to filter first) 

### Code to Create Trelliscope View - Housing ###

This activity will teach you how to create your own `trelliscope` displays as well as some basic functionality of 
the `datadr` package using the housing data set. We will be using the same data from the pre-made displays, 
but now we will illustrate the code that generates the `trelliscope` view. 
This tutorial will demonstrate how to generate your own plots and how to create 
and use cognostics to filter and sort the plots.

There are several key steps to creating a Trelliscope view that we will discuss below:
- Load the `trelliscope` package and other requisite packages
- Divide the data using `divide()` from the `datadr` package
- Get an initial feel for the data using tabular summaries
- Define the **panel** and **cognostics** functions
- Establish a connection to a visualization data base (vdb) using `vdbConn()` from the 
  `trelliscope` package
- Write `trelliscope` view files to the vdb using `makeDisplay()`
- Launch the `trelliscope` viewer using `view()`

#### Preliminaries ####

Let's begin by removing any (and all) left-over objects in the Global environment of the R session:

```{r eval = FALSE, results = "hide"}
# Clear the R workspace
rm(list = ls())
```

Now we'll load the necessary libraries.  Note that the housing data loads automatically with
the `housingData` package.

```{r eval = TRUE, results = "hide", message = FALSE}
# Load the trelliscope package if you haven't already
library(trelliscope)
library(housingData)

# You will need to replace the first part of path with the location where you
# unzipped the demonstration files
setwd("~/correct_path/housing_demo")
```

Let's look at the first part of the housing data, along with it's structure

```{r eval = TRUE, message = FALSE}
# Display first 6 rows of housing data
head(housing)

# Display the dimensions, column names, and data types:
str(housing)
```

#### Divide the Data ####

Using the `divide()` function of the `datadr` package, we are going to divide the data set 
by the variables **county** and **state** and thereby create a divided data frame (ddf), 
one of the primary data types in the `datadr` package.  Each element in the ddf is as subset of the
original housing dataset, containing the data for a unique county and state combination. 

```{r eval = TRUE, message = FALSE}
# We will create a distributed data frame by dividing our data by county and state
byCounty <- divide(housing, by = c("county", "state"), update = TRUE)

# Note that "byCounty" is a distributed data frame (ddf)
class(byCounty)
```

**ddf** objects have a printing method that shows the size of the object in terms of memory 
and other metadata related to the ddf:

```{r eval = TRUE}
# Show (print) the ddf object:
byCounty
```
Let's look at first division in the ddf. It will consist of a key-value pair.
The key should look something like "county=X|state=Y" and the value
should be the data frame corresponding to that key.

```{r eval = TRUE}
# Display the first division of the ddf
byCounty[[1]]
```

Exploratory data analysis often begins with computing a
variety of summary statistics.  The `datadr` package has some predefined functions 
for performing these calculations on ddfs:

### Check these
```{r eval = FALSE}
# Display the number of data divisions, corresponding to the number of unique counties
length(byCounty) 

# Column names in the data
names(byCounty)

# Data division keys (state & county names in this example)
getKeys(byCounty) 

# Look at summary statistics for each key-value pair:
summary(byCounty)
```

We can get a sense of the number of rows in each element of the ddf as well as the amount of 
memory taken up by each element using `splitRowDistn()` and `splitSizeDistn()`.

```{r eval = TRUE, message = FALSE}
# Percentiles of number of rows per division
splitRowDistn(byCounty) 

# Percentiles of number of bytes per division
splitSizeDistn(byCounty) 
```

You can access the elements of the distributed data frame (ddf) using the key or by index, 
just like you would with a traditional list.

```{r eval = TRUE}
# A data division can be accessed by by its named key or by number
byCounty[["county=Benton County|state=WA"]]
```

```{r eval = FALSE}
# If you wish to access the data frame by index 
byCounty[[176]] 
```

Finally, you can use the `drQuantile()` function to compute the sample quantiles for the elements in the ddf object.

```{r eval = TRUE}
# Look at quantiles of median list price/sqft 
priceQ <- drQuantile(byCounty, var = "medListPriceSqft")
xyplot(q~fval, data=priceQ, main="Median List Price/Sqft Quantiles")
```

#### Divide and Recombine ####

Suppose we are interested in figuring out the trend component of each time series in our ddf.
We can do this by creating a linear model for each subdivision and extracting the slope parameter. 
We wish to incorporate this information into our pre-existing ddf and use it in our analysis. 

```{r eval=T, message = F, results = "hide"}
# Calculate linear model for each data division to see the trend in prices

# Create a function to calculate a linear model and extract the slope parameter
lmCoef <- function(x) {
   data.frame(getSplitVars(x), slope=coef(lm(medListPriceSqft ~ time, data = x))[2])
}

# Test lmCoef on one division
kvApply(lmCoef, byCounty[[176]])

# Add the function transform to the DDF
byCountySlope <- addTransform(byCounty, lmCoef)

# Now look at data with the transformation
byCountySlope[[176]]

# Recombine the slope data into a single data.frame
countySlopes <- recombine(byCountySlope, combRbind)

# Look at the recombined data
head(countySlopes)
```

Sometimes you will want to actively combine two distributed data objects/frames together to create 
a new data set. We will demonstrate how to perform these types of operations using the `drJoin()` function.

```{r eval = T, message = F, results = "hide"}

# Look at geoCounty which contains more information about US counties
head(geoCounty)

# Divide geoCounty on county and state just like we did with the housing data
geo <- divide(geoCounty, by = c("county", "state"))
geo[[1]]

# Get some wikipedia data on counties and divide by county/state
wikiByCounty <- divide(wikiCounty, by = c("county", "state"))

# Join divided housing, geo and wiki data together
# This forms a Distributed Data Object (DDO)
joinedData <- drJoin(housing = byCounty, slope=byCountySlope, geo = geo, wiki=wikiByCounty)

# Note that this is no longer a distributed data frame
class(joinedData)

joinedData[[176]]

length(joinedData)

# Filter dataset to remove divisions without housing sales data
joinedData <- drFilter(joinedData, function(x) {
   !is.null(x$housing)
})

# See that the length has decreased - some data divisions have been removed
length(joinedData)

```

The data is now ready to be ingested into trelliscope. To use trelliscope, the user needs to define 
a visual data base and create basic functions for plotting. On top of this, a user can develop and 
use cognostics to improve data interpretability. A cognostic is usually, but not always, a summary 
statistic or some form of metadata to be included along with plots. These values can be useful in 
determining patterns or anomalies in visual displays. 

```{r eval = F, message = F}

# Define a visualization database directory where the plots and metadata
# will be saved. Unless a complete file path is specified, the vdb will be
# generated in the working directory. 
vdbConn("vdb_housing", autoYes=TRUE)
```

```{r eval = T}
# Define a plot function
timePanel <- function(x) {
   xyplot(medListPriceSqft + medSoldPriceSqft ~ time,
      data = x$housing, auto.key = TRUE, ylab = "Price / Sq. Ft.")
}

# Test the plot function on a single division
kvApply(timePanel, joinedData[[176]])

```

We have defined a simple plot function. It would be useful to define a set of cognostics that 
can give us a large set of angles with which to attack the data anlysis problem at hand. Some 
simple cognostics are included in the trelliscope package such as `cogMean()` and `cogRange()` 
which are self-explanatory. You are free to define any other measure of the data using the `cog()` function.  

```{r eval = T}
# Define a cognostics function: this is used to define information and 
# statistics that will be available in the Trelliscope UI for sorting and 
# filtering and also to display/link useful meta information.
priceCog <- function(a) { 
   x <- a$housing
   st <- getSplitVar(a, "state")
   ct <- getSplitVar(a, "county")
   zillowString <- paste(ct, st)
   zillowString <- gsub(" ", "-", zillowString)
   list(
      fips = cog(x$fips[1], desc = "fips code"),
      region = cog(state.region[state.abb == ifelse(st == "DC", "MD", st)]),
      division = cog(state.division[state.abb == ifelse(st == "DC", "MD", st)]),
      slope = cog(a$slope$slope, desc = "list price slope"),
      meanList = cogMean(x$medListPriceSqft),
      meanSold = cogMean(x$medSoldPriceSqft),
      listRange = cogRange(x$medListPriceSqft),
      soldRange = cogRange(x$medSoldPriceSqft),
      nObs = cog(length(which(!is.na(x$medListPriceSqft))), 
         desc = "number of non-NA list prices"),
      lat = cog(a$geo$lat, desc = "county latitude"),
      lon = cog(a$geo$lon, desc = "county longitude"),
      pop2013 = cog(log10(a$wiki$pop2013), desc = "log base 10 population in 2013"),
      wikiHref = cogHref(a$wiki$href, "wiki link"),
      zillowHref = cogHref(sprintf("http://www.zillow.com/homes/%s_rb/", zillowString), "zillow link")
   )
}

# Test on a single division
kvApply(priceCog, joinedData[[176]])

```

```{r eval = F}
# Create the display: this creates and saves display files and information in
# the vdb directory defined above
makeDisplay(joinedData,
   name = "list_sold_vs_time_datadr_tut",
   desc = "List and sold price over time",
   panelFn = timePanel, 
   cogFn = priceCog,
   width = 400, height = 400,
   lims = list(x = "same"))

# Open Trelliscope in a browser
myport <- 8100 # use this when running locally
# myport <- Sys.getenv("TR_PORT") # use this on demo cluster
view(port=myport)
```
